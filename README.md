# SLM Reasoning Experiments

This repository is a sandbox for experimenting with **Small Language Models (SLMs)** focused on enhancing their **reasoning capabilities**.  
The main goal is to explore different algorithms and **internal iteration strategies** that could enable small models to achieve more robust and efficient reasoning.

## Goals
- Test various iterative reasoning approaches in SLMs.  
- Compare algorithms and techniques for self-reflection, verification, and refinement.  
- Evaluate the impact on accuracy, coherence, and computational efficiency.  

## Repository Structure
- `notebooks/` â†’ Exploratory tests and quick prototypes.  
- `src/` â†’ Core implementations of algorithms and utilities.  
- `experiments/` â†’ Scripts and configurations for running experiments.  
- `results/` â†’ Metrics, logs, and analysis of outcomes.  

## Status
This project is in an exploratory phase. Initial results will focus on **comparative testing of reasoning algorithms** applied to SLMs, with a special focus on internal iterations and their effect on performance.

## Future Work
- Integrate standard reasoning benchmarks.  
- Explore lightweight fine-tuning methods (LoRA, adapters, etc.) to boost reasoning.  
- Analyze trade-offs between computational cost and achieved improvements.  

---

ðŸ“Œ Work in progress.

